{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7807ab61-c7a3-49df-abf6-520859b1d53f",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a609ce2-1ac0-4a70-b637-c554e1f56cc8",
   "metadata": {},
   "source": [
    "Serialising and deserialising objects is useful for persistence of data (even after a program has terminated) and/or transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b311673-51eb-471a-a8f9-53507d58e249",
   "metadata": {},
   "source": [
    "# 01 - Pickling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086655b-ae3f-4c14-866f-3f7d42e0cf7a",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccfc6f-c7e5-48cd-894c-eb232d027ba0",
   "metadata": {},
   "source": [
    "This is a python-specific mechanism to serialise/deserialise objects using **binary** (by default) representation.\n",
    "\n",
    "While pickling applies to *more* than just python dictionaries, we will focus on dictionaries here because of JSON - it's easy to serialise/deserialise them into JSON.\n",
    "\n",
    "But not all data types are serialisable; `datetime`s, for example, don't serialise without loss of data, but there are 3rd party libraries that solve these problems (marshmallow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5d5c8-bbe8-4c95-ba75-56bcf2d1ae46",
   "metadata": {},
   "source": [
    "**Object/Data Marshalling** is the process of serialising **and** deserialising objects/data:\n",
    "\n",
    "`obj -- serialise --> 0101001110011... -- deserialise --> obj`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883f6e7-2aa9-46de-b2b1-dcb7aa22394c",
   "metadata": {},
   "source": [
    "Unpickling data can be **dangerous** because they can **execute code**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ef357-e977-43b9-801d-9b59b5dec2d9",
   "metadata": {},
   "source": [
    "##### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab684dc3-f81e-4aee-bd58-995c8bbbad68",
   "metadata": {},
   "source": [
    "```import pickle```\n",
    "\n",
    "`dump` -> pickle to file\n",
    "\n",
    "`load` -> unpickle from file\n",
    "\n",
    "`dumps` -> returns a string pickled representation that can be stored in a variable\n",
    "\n",
    "`loads` -> unpickles from a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b83d4-fa7b-42f8-bf43-494cc92e8713",
   "metadata": {},
   "source": [
    "##### Equality and Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6bd14-4f41-4f5b-9d39-ce48978f09a5",
   "metadata": {},
   "source": [
    "A pickled object does not contain information of its ID. Therefore, if a dictionary `dict_1` is pickled and then unpickled, the final dictionary `dict_2` will have a different ID to the original.\n",
    "\n",
    "`dict_1 == dict_2` but `dict_1 is not dict_2`\n",
    "\n",
    "Serialising/Deserialising data behaves very similar to making deepcopies. If we deepcopy an object which contains two identical references to the same object, then, the copy will ensure that the relationship is maintained. To elaborate with an example:\n",
    "\n",
    "```python\n",
    "my_list = [1, 2]\n",
    "l1 = ['a', 'b', my_list, my_list]\n",
    "\n",
    "l1[2] == l1[3] --> True\n",
    "l1[2] is l1[3] --> True\n",
    "\n",
    "l2 = deepcopy(l1)\n",
    "l2 -> ['a', 'b', [1, 2], [1, 2]]\n",
    "\n",
    "l2[2] == l2[3] --> True\n",
    "l2[2] is l2[3] --> True\n",
    "```\n",
    "\n",
    "So Python sees the shared reference of `l1[2]` and `l2[3]` pointing to `my_list` and it replicates that relationship in the copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a515702-7860-4e60-b22c-6267ac896776",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb12ce-8fc9-4f9c-8538-5c9e1894fff7",
   "metadata": {},
   "source": [
    "##### `.dumps()` and `.loads()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc8355-3d91-4242-ad59-3e2227d6f7a3",
   "metadata": {},
   "source": [
    "We can pickle **strings**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df82eedf-1fd1-4592-a28d-603d825500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a34974-b983-4ef7-85df-594784fac5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x15Python Pickle Peppers\\x94.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps('Python Pickle Peppers')\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149ba4c7-09f7-416f-ba53-0281cda6519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python Pickle Peppers'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d21217-5163-4e9a-b735-092856b9a6a9",
   "metadata": {},
   "source": [
    "And **floats/integers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea45278f-6bb0-4a54-8c12-4077475e6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00G@\\t\\x1e\\xb8Q\\xeb\\x85\\x1f.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps(3.14)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf76488-11a8-4028-ba0f-6055fde36788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4b451-37df-475b-92bf-ddbebab566e0",
   "metadata": {},
   "source": [
    "And **sets**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759a4f5d-b59d-4b55-af4c-11fcbc157869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8f\\x94(\\x8c\\x01a\\x94K\\n\\x8c\\x01b\\x94\\x90.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps({'a', 'b', 10})\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08cf3ed-3953-4918-934e-458d68957077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 'a', 'b'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405dbf9-e01e-4751-9378-b5a1eb552a76",
   "metadata": {},
   "source": [
    "And **lists/tuples**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de90d34-8340-4877-8195-2e110254991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(K\\nK\\x14\\x8c\\x01a\\x94\\x8c\\x01b\\x94K\\x1e\\x87\\x94e.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [10, 20, ('a', 'b', 30)]\n",
    "ser = pickle.dumps(l1)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c7745a-df58-45e0-84b4-8086f06c9e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, ('a', 'b', 30)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = pickle.loads(ser)\n",
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde68b58-57cf-44ad-91bf-f4e815dc4a79",
   "metadata": {},
   "source": [
    "But remember that the IDs will **change**. They are **equal** but not **identical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4748737-5fc4-48d1-8f54-be7d25c6be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 == l2 = True\n",
      "l1 is l2 = False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{l1 == l2 = }\")\n",
    "print(f\"{l1 is l2 = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc83bc2-4e88-4075-81fc-8550acb3465e",
   "metadata": {},
   "source": [
    "And **dictionaries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c950c44-396e-4099-97e3-a0a6ec9bc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x8b\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x01a\\x94Kd\\x8c\\x01b\\x94]\\x94(K\\x01K\\x02K\\x03e\\x8c\\x01c\\x94K\\x01K\\x02K\\x03\\x87\\x94\\x8c\\x01d\\x94}\\x94(\\x8c\\x01x\\x94\\x8c\\x08builtins\\x94\\x8c\\x07complex\\x94\\x93\\x94G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00\\x86\\x94R\\x94\\x8c\\x01y\\x94\\x8c\\x08datetime\\x94\\x8c\\x08datetime\\x94\\x93\\x94C\\n\\x07\\xe8\\x01\\x1c\\x13: \\x07\\x94\\xda\\x94\\x85\\x94R\\x94uu.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "d = {\n",
    "    'a': 100,\n",
    "    'b': [1, 2, 3],\n",
    "    'c': (1, 2, 3),\n",
    "    'd': {'x': 1 + 1j, 'y': datetime.utcnow()}\n",
    "}\n",
    "\n",
    "ser = pickle.dumps(d)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a9451d-e150-4fa9-984c-def79398b226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 100,\n",
       " 'b': [1, 2, 3],\n",
       " 'c': (1, 2, 3),\n",
       " 'd': {'x': (1+1j), 'y': datetime.datetime(2024, 1, 28, 19, 58, 32, 496858)}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac9c49-b7bf-4984-8a4f-cc84a906c556",
   "metadata": {},
   "source": [
    "As mentioned in the lecture, shared reference relationships are maintained with serialising/deserialising just like with deepcopies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f57e95-5e6e-44f2-8dc7-b608661df944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'a': 10, 'b': 20}\n",
    "d = {'x': 100, 'y': my_dict, 'z': my_dict}\n",
    "\n",
    "print(d['y'] == d['y'])\n",
    "print(d['y'] is d['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23462cc6-437b-4a7f-b680-78caf257ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ser = pickle.dumps(d)\n",
    "d2 = pickle.loads(ser)\n",
    "\n",
    "print(d2['y'] == d2['y'])\n",
    "print(d2['y'] is d2['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9168a-990e-46a9-a149-d2f430767e8c",
   "metadata": {},
   "source": [
    "# 02 - JSON Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a651b-dc8f-4ba6-8276-7e86edd1c4d9",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef773b-6770-41c9-be76-d65aa106a9ec",
   "metadata": {},
   "source": [
    "JSON has just a few data types it supports:\n",
    "\n",
    "* **Strings**: must be delimited by double quotes\n",
    "* **Booleans**: the values `true` and `false`\n",
    "* **Numbers**: can be integers, or floats (including exponential notation, `1.3E2` for example), but are all considered **floats** in the standard\n",
    "* **Arrays**: an **ordered** collection of zero or more items of any valid JSON type\n",
    "* **Objects**: an **unordered** collection of `key:value` pairs - **the keys must be strings (so delimited by double quotes)**, and the values can be any valid JSON type.\n",
    "* **NULL**: a null object, denoted by `null` and equivalent to `None` in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7434f-240f-436c-9e4c-cbaa9c9c298b",
   "metadata": {},
   "source": [
    "Python dictionaries are **objects** while JSON is essentially a **string**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c0b51-c4e8-4949-baf9-2bc9d9dc731c",
   "metadata": {},
   "source": [
    "##### Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebabcd-194d-4d32-aab5-046227e211f2",
   "metadata": {},
   "source": [
    "- JSON keys must be strings, but python dictionary keys just need to be hashable. So if you had an `integer` as a key in your python dictionary, how will you serialise it?\n",
    "- JSON value types are limited to those above. So we can't have tuples, datetime objects, `Decimal`'s `Fraction`'s, custom classes - how do we serialise these back to their original object?\n",
    "\n",
    "Solution? **Custom Serialisation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2b942-b371-4b64-a0d4-4a6b0066022c",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ce692-6d7c-48cf-8b53-81369f0f153b",
   "metadata": {},
   "source": [
    "Serialisation and deserialisation is very similar to pickling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d9ca9-c14d-4824-9abb-c6ec458575b3",
   "metadata": {},
   "source": [
    "```import json```\n",
    "\n",
    "`dump` -> dump to file\n",
    "\n",
    "`load` -> load from file\n",
    "\n",
    "`dumps` -> dumps python object to a string containing JSON\n",
    "\n",
    "`loads` -> loads a string containing JSON into a python object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999f54e-52bc-4e08-a886-59f8ed4bbecb",
   "metadata": {},
   "source": [
    "`dump` and `dumps` have additional arguments for controlling serialisation:\n",
    "- `skipkeys: Bool = False`: if we are dumping a python dictionary, then the key must be one of the basic types and hashable. If set to true, then unserialisable keys will be skipped.\n",
    "- `indent: int = None`: useful for human readability\n",
    "- `separators: tuple = (\", \", \": \")`: the first argument customises how key-value pairs are separated and the 2nd customises how keys are separated from their values.\n",
    "\n",
    "   We can use this to compact the JSON object for small performance improvements.\n",
    "\n",
    "  Note, we still need a valid JSON, so the most compact form is having `indent = None` and `separators = (\",\",\":\")`\n",
    "- `sort_keys: bool = False`: if `True` the JSON string will have sorted keys. Since the keys will be strings, they will be alphanumerically sorted.\n",
    "\n",
    "and more..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238e445-351c-4ff1-9487-46c003b42c1b",
   "metadata": {},
   "source": [
    "We have a `pprint` equivalent for JSON which is achieved using the `indent` parameter of `json.dumps()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4fe7d01-c1ec-4402-85bc-5d2de84eef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 100, \"b\": 200, \"c\": [1, 2, 3]} \n",
      "\n",
      "{\n",
      "  \"a\": 100,\n",
      "  \"b\": 200,\n",
      "  \"c\": [\n",
      "    1,\n",
      "    2,\n",
      "    3\n",
      "  ]\n",
      "} \n",
      "\n",
      "{\n",
      "___\"a\": 100,\n",
      "___\"b\": 200,\n",
      "___\"c\": [\n",
      "______1,\n",
      "______2,\n",
      "______3\n",
      "___]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "d1 = {'a': 100, 'b': 200, 'c': [1, 2, 3]}\n",
    "d1_json = json.dumps(d1)\n",
    "\n",
    "print(json.dumps(d1), \"\\n\")\n",
    "print(json.dumps(d1, indent=2), \"\\n\")\n",
    "print(json.dumps(d1, indent='___'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab16fb-7be1-42f9-a4fe-edd8d4588d35",
   "metadata": {},
   "source": [
    "##### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8c192-8fc1-4a4e-9eb0-3a9aa74e9492",
   "metadata": {},
   "source": [
    "As we said, json keys must be strings. So what if we serialise a deserialise objects with non-string keys? Do we get the same object back? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e2591f-33eb-4b96-8373-074fc3e50844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 100, '2': 200}\n"
     ]
    }
   ],
   "source": [
    "d1 = {1: 100, 2: 200}\n",
    "d1_json = json.dumps(d1, indent=2)\n",
    "d2 = json.loads(d1_json)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086fb64-7ad2-4260-8be6-7662132b7589",
   "metadata": {},
   "source": [
    "The keys are **different**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1280bf-3805-42ad-94e3-43a638c27b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 == d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d99de-224a-4893-9d03-43752d60f42a",
   "metadata": {},
   "source": [
    "##### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035af8d-a580-4607-b67b-9b9f17baa53b",
   "metadata": {},
   "source": [
    "How will Python handle unsupported types such as tuples for the dictionary values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0b29a23-2cb8-415f-8be2-d6acf7e07442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "d = {'a': (1, 2, 3)}\n",
    "ser = json.dumps(d)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60bf0d89-e802-4019-a0ca-83e31c425e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "deser = json.loads(ser)\n",
    "print(deser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ab252-b234-447b-a9c0-a05c7d588dac",
   "metadata": {},
   "source": [
    "The tuple was coerced into a list. Therefore, the value is **different**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f91a9af-28e1-471a-b735-482d774e6999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser == deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8a13f-c6ea-4d10-a231-dfd03087c524",
   "metadata": {},
   "source": [
    "But, python at least tried to find the most similar thing to a tuple. With more complex objects such as datetime objects, `Decimal`s and class instances, it will raise `TypeError`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45bb3884-94c6-4dc0-b6a6-6eb31de4c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of type datetime is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "try:    \n",
    "    json.dumps({'a': datetime(2024, 12, 23, 13, 37), 'b': Decimal(0.5)})\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137a359-4e7d-4c49-a259-ec3c991a9e60",
   "metadata": {},
   "source": [
    "# 03 - Custom JSON Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73862f7-4335-422e-96b4-ac51eec3c814",
   "metadata": {},
   "source": [
    "##### `datetime` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7c189-6730-4643-9d86-c7d204a5720f",
   "metadata": {},
   "source": [
    "Python cannot serialise certain data types by itself but we can tell it how to. `json.dump()` and `json.dumps()` have a parameter caled `default`. This takes a callable that takes only one argument which is called on any objects that cannot be serialised by python itself. For example the `str()` will convert any unserialiable object to its string representation which can be serialised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969c6b0-2fe7-4306-8b30-a6d8e19626cf",
   "metadata": {},
   "source": [
    "Often we will come up with our custom format or use industry standards. For example, datetime objects use the **ISO 8601** (https://en.wikipedia.org/wiki/ISO_8601).\n",
    "\n",
    "This has the format of:\n",
    "*YYYY-MM-DD***T***HH:MM:SS*\n",
    "\n",
    "The **T** is a character to separate the date from the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a702e8-4485-4228-a50e-538e5744884b",
   "metadata": {},
   "source": [
    "Note: the `str` representation of a time is not the same as the ISO format; it's similar but more human readable. As you can see it does not contain the required **T** character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e28521e2-ba77-403c-8390-19d3b8e38427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17 17:45:31.612621'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf4fee-9a2f-4fb4-911f-b970741ca606",
   "metadata": {},
   "source": [
    "If you want to format the year, month, day, time etc, in a particular way, use **`.strftime()` method** of datetime objects. \n",
    "\n",
    "The reverse of this method is `strptime()` which takes a string in a particular format and converts it to a datetime object.\n",
    "\n",
    "In the format, you indicate the different time components with directives. For example, `'%Y'` returns a 4 digit year e.g. 2012, where `'&y'` returns a year without century, zero-padded e.g. 2012 -> 12.\n",
    "\n",
    "Here's our custom, simple ISO format (without including timezones etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "141736fd-077b-450f-9e6a-dca98e686856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17T17:52:25'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_iso(dt):\n",
    "    return dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "format_iso(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e951697-f05e-4067-a1ca-d289fd75518c",
   "metadata": {},
   "source": [
    "Alternatively, we can use the inbuilt ISO format in `datetime` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b7df0e8-c35e-4bb4-a231-d8fdda84db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17T17:53:46.213212'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904aeda-bede-48fd-b323-16f528b61d34",
   "metadata": {},
   "source": [
    "Now lets serialise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd798d53-d909-40a3-aff5-c9d5a0ebb752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\": \"2024-02-17T17:55:55\"}\n"
     ]
    }
   ],
   "source": [
    "log_record = {'time': datetime.utcnow()}\n",
    "print(json.dumps(log_record, default=format_iso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732cd83-7343-49f0-b67c-15175bac5b56",
   "metadata": {},
   "source": [
    "##### `singledispatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd074e4b-3d78-46bc-abcd-f1c862946dc8",
   "metadata": {},
   "source": [
    "If our `log_record` dictionary contained an unserialisable type that was *not* a datetime object, we're going to run into issues because the same callable will be used on it.\n",
    "\n",
    "We can get around this by checking the type of argument in the callable and handling it that way. For example, if we only had `datetime`s and `set`, this could work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d371e7-f9ce-4e6d-b6da-42f93bb3dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_json_formatter(arg):\n",
    "    if isinstance(arg, datetime):\n",
    "        return arg.isoformat()\n",
    "    elif isinstance(arg, set):\n",
    "        return list(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e3744-c981-46b4-8cc3-7c3af49e7870",
   "metadata": {},
   "source": [
    "Obviously this doesn't scale well, so we should move over to using a `singledispatch`:\n",
    "\n",
    "Let's write a single dispatcher that registers specific implementations for `datetime`, `set`, `Decimal` - and for anything else, use their string representation. \n",
    "\n",
    "To do that, we first need to write the default behaviour which is stringifying the object. Then, we register our individual types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9717af38-1af3-4871-bf6a-95d0d15ccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import singledispatch\n",
    "from decimal import Decimal\n",
    "\n",
    "@singledispatch\n",
    "def json_format(arg):\n",
    "    return str(arg)\n",
    "\n",
    "@json_format.register(datetime)\n",
    "def _(arg):\n",
    "    return arg.isoformat()\n",
    "\n",
    "@json_format.register(set)\n",
    "def _(arg):\n",
    "    return list(arg)\n",
    "\n",
    "@json_format.register(Decimal)\n",
    "def _(arg):\n",
    "    return f\"Decimal({str(arg)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83c07160-2f44-43f4-b2b4-3ea8dd627ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"time\": \"2024-02-17T18:26:58.562067\",\n",
      "  \"message\": \"Created new person\",\n",
      "  \"person\": \"Person(name=John, age=24)\",\n",
      "  \"complex_number\": \"(1+1j)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.create_dt = datetime.utcnow()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self.name}, age={self.age})'\n",
    "\n",
    "log_record = dict(\n",
    "    time=datetime.utcnow(),\n",
    "    message='Created new person',\n",
    "    person=Person('John', 24),\n",
    "    complex_number = 1 + 1j,\n",
    ")\n",
    "\n",
    "print(json.dumps(log_record, indent=2, default=json_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda76b2-ce0d-4b62-a256-d71edcf669ad",
   "metadata": {},
   "source": [
    "# 04 - Custom Encoding using JSONEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7b297-647f-419a-b1db-fbed03d92a0f",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cae5d-e651-45c4-909e-17aef18e94ca",
   "metadata": {},
   "source": [
    "Python already uses the `JSONEncoder` class in the `json` module we use `json.dumps()` for serialisation.\n",
    "\n",
    "The `JSONEncoder` shares many arguments with `dump`/`dumps`: `default`, `skipkeys`, `sort_keys`, `indent`, `separators`, ...\n",
    "\n",
    "But `dump`/`dumps` has one extra: `cls`: this allows us to specify our **own** version of `JSONEncoder` to be used when `dump`/`dumps` runs.\n",
    "\n",
    "The reason why we would want to make our own `JSONEncoder` class is so that we can define our arguments (`default`, `skipkeys`, `indent`, etc.) once and then apply it to all of our `json.dumps()` calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aceb0-a44a-479f-8a8c-e430206d2cc3",
   "metadata": {},
   "source": [
    "**Procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db9a92-c1c6-43fe-885f-a6d23a32efc8",
   "metadata": {},
   "source": [
    "1. Subclass `JSONEncoder`.\n",
    "2. Customise initialiser of the **parent** class with the specific arguments that we want. (`super().__init__(skipkeys=True, allow_nan=False)`.)\n",
    "3. Override the `default` method if we want. If we do not, we can auto-delegate back to the parent class. `else: return super().default(self, arg)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9808fea-3bea-49c7-ab45-184736572a6a",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a5b1e-a5c8-4882-a33a-34561f63b7b9",
   "metadata": {},
   "source": [
    "To get a handle on the default encoder, we just create an instance of `JSONEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9c2975-8719-4077-b74e-d7f8458236ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "null\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "default_encoder = json.JSONEncoder()\n",
    "print(default_encoder.encode(True))\n",
    "print(default_encoder.encode(None))\n",
    "print(default_encoder.encode((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787540a6-0f14-4e41-8413-3e6bb2948c86",
   "metadata": {},
   "source": [
    "Now for our custom one. Note that our `CustomJSONEncoder` inherits from `json.JSONEncoder`. `json.dumps()` passes all of its arguments to the `cls` argument, which is `CustomJSONEncoder` in our case, as `*args` and `**kwargs` .\n",
    "\n",
    "We don't do anything we these `*args` and `**kwargs` but we do define which ones we want and explicitly pass them to the superclass. When `encode` is called on our `customJSONEncoder`, it will call the `encode` method of the superclass (`json.JSONEncoder`), which will make use of our explictly passed parameters that we initialised earlier in the superclass.\n",
    "\n",
    "The entire serialisation implementation is done in the superclass `json.JSONEncoder`, except those methods that we've overridden such as `default`. \n",
    "\n",
    "So, when `json.dumps()` requires `default()` to pass a particular value, it will use our overridden implementation, not the one from the superclass.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b484c168-23ec-4d09-9777-f248c83d4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            skipkeys=True,\n",
    "            allow_nan=False,\n",
    "            indent='___',\n",
    "            separators=('',' = ')\n",
    "        )\n",
    "\n",
    "    # overriding original default with ours\n",
    "    def default(self, arg):\n",
    "        if isinstance(arg, datetime):\n",
    "            datetime_dict = dict(\n",
    "                datatype=\"datetime\",\n",
    "                iso=arg.isoformat(),\n",
    "                date=arg.date().isoformat(),\n",
    "                time=arg.time().isoformat(),\n",
    "                year = arg.year\n",
    "            )\n",
    "            return datetime_dict\n",
    "        else:\n",
    "            super().default(arg)\n",
    "\n",
    "custom_encoder = CustomJSONEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44159d31-ff0c-4d87-8fb7-4e6dd697d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "___\"datatype\" = \"datetime\"\n",
      "___\"iso\" = \"2024-02-24T14:44:30.597643\"\n",
      "___\"date\" = \"2024-02-24\"\n",
      "___\"time\" = \"14:44:30.597643\"\n",
      "___\"year\" = 2024\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(custom_encoder.encode(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fe972c2-56f2-4102-bafd-a13d919b2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of type set is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(custom_encoder.encode({1, 2, 3}))\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938fb55-4f99-4cf8-aef5-48554f1273e8",
   "metadata": {},
   "source": [
    "Now for dumping. Note that we pass the *class* itself and not the class instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b613d77-4205-49b7-8045-723aef255b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "___\"name\" = \"test\"\n",
      "___\"time\" = {\n",
      "______\"datatype\" = \"datetime\"\n",
      "______\"iso\" = \"2024-02-18T16:34:19.151692\"\n",
      "______\"date\" = \"2024-02-18\"\n",
      "______\"time\" = \"16:34:19.151692\"\n",
      "______\"year\" = 2024\n",
      "___}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "my_dict = dict(name='test', time=datetime.now())\n",
    "print(json.dumps(my_dict, cls=CustomJSONEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8f02f-daa9-470b-b72d-ef99c8356aad",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "- You might've noticed the `*args, **kwargs` in our custom class' `__init__`. This is because `json.dumps()` will pass the default arguments of `json.dumps()` to the class in its `cls` argument. In other words, `json.dumps(my_dict)` is identical to `json.dumps(my_dict, skipkeys=False, allow_nan=True, ...)` because those are the default arguments.\n",
    "- `default` does not need to return a single value. In our case, we've serialised the datetime object into a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c73cf1-14b6-4c5e-a746-39b9d7d80cd2",
   "metadata": {},
   "source": [
    "# 05 - Custom JSON Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4066f-5684-4119-ae32-5d21475a3cff",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0dcf3f-e1e8-4265-8325-efa7c3525438",
   "metadata": {},
   "source": [
    "##### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa972149-86c0-4073-9074-e085a86a6cc8",
   "metadata": {},
   "source": [
    "When we use `json.load()` / `json.loads()`, the simple standard types i.e. strings, booleans, numbers (int/float), arrays and objects (dictionaries) will work out the box. \n",
    "\n",
    "**`load()`/`loads()` has some optional arguments:**\n",
    "- `object_hook`: **Callable** - This is called on every object (dictionary) including the root object (dictionary) that encloses the entire json object. This callable returns another dictionary which replaces the original object. This is very similar to the `default` argument we saw in the `dump`/`dumps` functions - but works for decoding instead of encoding.\n",
    "\n",
    "    For example, if we had:\n",
    "  ```python\n",
    "  data = {'username': 'John',\n",
    "          'createdAt': {objecttype='datetime', value='2018-10-21T09:14:15'}\n",
    "  ```\n",
    "  We could write a function `custom_decoder` that takes a dictionary, looks to see if it has a key called with `objecttype='datetime' and if so, converts the value to a datetime object and returns the new decoded dictionary.\n",
    "\n",
    "  So, `custom_decoder(data) ->`\n",
    "  ```python\n",
    "  data = {'username': 'John',\n",
    "          'createdAt': {objecttype='datetime', value=Datetime(2024, 10, 21, 09, 14, 15}\n",
    "          }\n",
    "  ``` \n",
    "\n",
    "\n",
    "    Note: when `object_hook` is provided, this procedure only occurs *after* the initial `deserialisation` - that which occurs when no `object_hook` is provided; that is, `object_hook` and `object_pairs_hook` receives a **parsed** object which may have be parsed using one of the `parse_...` arguments **first** (see below).\n",
    "\n",
    "    This initial deserialisation converts e.g. `j = '''{\"a\": [1, 2]}'''` into a dictionary where the keys and values are the appropriate types, e.g. '[1, 2]' into a list object.\n",
    "  ```python\n",
    "  j = '''\n",
    "      { # root dictionary\n",
    "          \"a\": 1, \n",
    "          \"b\": {\n",
    "             \"sub1\": [1, 2, 3],\n",
    "             \"sub2\": {\n",
    "                   \"x\": 100,\n",
    "                   \"y\": 200\n",
    "              }\n",
    "          }\n",
    "      }     \n",
    "      '''\n",
    "  ```\n",
    "  `sub2`, `b` and `root` are all dictionaries that will be passed to the `object_hook` callable in that order - from the inner to the out. The `root` is always called last.\r",
    "<br/><br/>\n",
    "- `object_pairs_hook`: Related to `object_hook`. We can't use both at the same time; if both specified, `object_hook` ignored. First note that order of items in your json string is not necessarily preserved upon deserialising, but lists preserve order: deserialising '[1, 2, 3]' will always be `[1, 2, 3]`. `object_hook_pairs` behaves identical to `object_hook` except instead of passing a dictionary to the callable, a list of key-value tuples will be passed instead:\n",
    "    - `object_hook` recevies: `{\"a\": 1, \"b\": 2}`\n",
    "    - `object_pairs_hook` receives: `[ (\"a\", 1), (\"b\", 2) ]`\n",
    "\n",
    "    With this, we are guaranteed order of keys seen in the initial json string.<br/><br/> \n",
    "- `parse_float`, `parse_int`, `parse_constant`: **Callable** with single str argument - Remember that we could custom serialise `Fraction(3, 2)` to the number 1.5. Well, what if we got a JSON containing the number 1.5 and we wanted to deserialise to `Fraction(3, 2)`? \n",
    "\n",
    "    This would require overriding the **initial deserialisation** that occurs before `object_hook`. Depending on what the value is in the JSON, we would use either `parse_float`, `parse_int` or `parse_constant` (relevant for Infinity, NaN, etc.) to override its deserialisation before. Note that we cannot override strings. Here's an example:\n",
    "\n",
    "    ```python\n",
    "    from decimal import Decimal\n",
    "\n",
    "    def make_decimal(arg: str):\n",
    "        return Decimal(arg)\n",
    "    j = '''{\"a\": 100.5}'''\n",
    "    res = json.loads(j, parse_float=make_decimal)\n",
    "\n",
    "    res -> {\"a\": Decimal('100.5')}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02cf2d-6818-4e29-8417-03d4b4feeba2",
   "metadata": {},
   "source": [
    "##### Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08764397-9721-4cd4-9769-f3a5efa3d103",
   "metadata": {},
   "source": [
    "We need to know the structure of the JSON data in order to perform custom **deserialisation**. This structure is called a **schema** - a pre-defined agreement on how the JSON is going to be **serialised**.\n",
    "\n",
    "The schema does not need to be for the entire JSON; it can be for subcomponents only.\n",
    "\n",
    "This is an example JSON schema for dealing with fractions:\n",
    "```python\n",
    "j = '''\n",
    "    {\n",
    "        \"cake\": \"yummy chocolate cake\",\n",
    "        \"myShare\": {\n",
    "            \"objecttype\": \"fraction\",\n",
    "            \"numerator\": 1,\n",
    "            \"denominator\": 8\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "```\n",
    "\n",
    "We can use this to create a `Fraction` object with the appropriate numerator and denominator that will replace the original value of the `myShare` key. \n",
    "\n",
    "As you can imagine, we can define numerous dictionaries with different `objecttype` and handle each of them accordingly. \n",
    "\n",
    "The way to do this in a *less clunky* way is using `object_hook`. This is like the decode equivalent of the `default` argument which was used for encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1035fc9-c743-42f2-9aa3-67c679b5c085",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71a208-8d0b-4d76-8cf0-d80decaa92fc",
   "metadata": {},
   "source": [
    "Let's make some JSON data and write our custom decoder which takes a dictionary and **replaces it** with an appropriate python type. We will take datetimes strings and parse them into datetime objects and fraction strings and parse them into Fraction objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05d45b6-69ee-4055-85ca-9501bb186c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cake': 'yummy chocolate cake',\n",
      " 'myShare': Fraction(1, 8),\n",
      " 'times': {'created': datetime.datetime(2018, 10, 21, 9, 14, 15),\n",
      "           'updated': datetime.datetime(2018, 10, 22, 10, 0, 5)}}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from pprint import pprint\n",
    "from fractions import Fraction\n",
    "\n",
    "j = '''\n",
    "    {\n",
    "        \"times\": {\n",
    "            \"created\": {\n",
    "                \"objecttype\": \"datetime\",\n",
    "                \"value\": \"2018-10-21T09:14:15\"\n",
    "                },\n",
    "            \"updated\": {\n",
    "                \"objecttype\": \"datetime\",\n",
    "                \"value\": \"2018-10-22T10:00:05\"\n",
    "                }\n",
    "            },\n",
    "\n",
    "        \"cake\": \"yummy chocolate cake\",\n",
    "        \"myShare\": {\n",
    "            \"objecttype\": \"fraction\",\n",
    "            \"numerator\": 1,\n",
    "            \"denominator\": 8\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "\n",
    "def custom_decoder(arg: dict):\n",
    "    if \"objecttype\" in arg:\n",
    "        if arg[\"objecttype\"] == \"datetime\":\n",
    "            return datetime.strptime(arg[\"value\"], \"%Y-%m-%dT%H:%M:%S\")\n",
    "        \n",
    "        elif arg['objecttype'] == 'fraction':\n",
    "            return Fraction(arg['numerator'], arg['denominator'])\n",
    "\n",
    "        return arg\n",
    "\n",
    "    else:\n",
    "        return arg\n",
    "\n",
    "pprint(json.loads(j, object_hook=custom_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022befb5-8fe0-421a-830e-bc0df6d44b0f",
   "metadata": {},
   "source": [
    "We **need** the `return arg` blocks because the root dictionary of the JSON will always be passed to the `object_hook` callable. Without the block, when the root dictionary is passed in, the decoder will return `None` and it'll be replaced with `None`. Therefore, `json.loads()` returns `None` overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3c802-e244-4afa-a7d7-6feec027155a",
   "metadata": {},
   "source": [
    "An example of `object_pairs_hook` can be found in the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928d198-9de0-43a1-aadd-3cd226207a57",
   "metadata": {},
   "source": [
    "# 06 - Using JSONDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776272d9-98fa-4277-a7f0-870766cb6066",
   "metadata": {},
   "source": [
    "Instead of using an `object_hook`, we can create a custom decoder to override the `json.JSONDecoder` that is called with every `json.loads()`. Both approaches are fine but the reason why we'd want to do it this way is for more consistent usage of our decoder as well as hardcoding in some default arguments in the `json.loads()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e39a3b2-3110-48d2-ae1f-f9d3f7792794",
   "metadata": {},
   "source": [
    "Just like we can use a subclass of `JSONEncoder` to customize our json encodings, we can use a subclass of the default `JSONDecoder` class to customize decoding our json strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27040dd-251a-432f-bb59-cecc7ab6ed31",
   "metadata": {},
   "source": [
    "It works quite differently from the `JSONEncoder` subclassing though.\n",
    "\n",
    "When we subclass `JSONEncoder` we override the `default` method which then allows us to intercept encoding of specific types of objects, and delegate back to the parent class what we don't want to handle specifically.\n",
    "\n",
    "With the `JSONDecoder` class we override the `decode` function which passes us the **entire** JSON as a **string** and we have to return whatever Python object we want, which is usually a dictionary. There's no delegating anything back to the parent class unless we want to completely skip customizing the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "656ed5a8-5070-4716-bd66-f9cc3f871ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0affc79-a28a-463c-aee4-21bb351094e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = '''\n",
    "    {\n",
    "        \"a\": 100,\n",
    "        \"b\": [1, 2, 3],\n",
    "        \"c\": \"python\",\n",
    "        \"d\": {\n",
    "            \"e\": 4,\n",
    "            \"f\": 5.5\n",
    "        }\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca4be095-c910-4062-9da8-da8c38b06a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecoder(json.JSONDecoder):\n",
    "    def decode(self, arg: str):\n",
    "        print(\"decode:\", type(arg), arg)\n",
    "        return \"a simple string object\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66dfe464-242c-4374-815f-79761e6ebe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode: <class 'str'> \n",
      "    {\n",
      "        \"a\": 100,\n",
      "        \"b\": [1, 2, 3],\n",
      "        \"c\": \"python\",\n",
      "        \"d\": {\n",
      "            \"e\": 4,\n",
      "            \"f\": 5.5\n",
      "        }\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = json.loads(j, cls=CustomDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c513520f-63b7-4c34-9ad4-ced88f87677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a simple string object'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847039a-ca3e-4b33-925a-0a9fcf14f2d6",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "**Note**:\n",
    "\n",
    "if we only want to override the defaults of `json.JSONDecoder`, we don't need to create a new custom class; instead, we can just instantiate an instance of `json.JSONDecoder` with those hardcoded arguments and use the `decode` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cefb81e5-67e6-4206-9b44-700a974a864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 100,\n",
      " 'b': [1,\n",
      "       2,\n",
      "       3],\n",
      " 'c': 'python',\n",
      " 'd': {'e': 4,\n",
      "       'f': Decimal('5.5')}}\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from pprint import pprint\n",
    "CustomDecoder = json.JSONDecoder(parse_float=Decimal)\n",
    "res = CustomDecoder.decode(j)\n",
    "pprint(res, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4c192-8076-4d7d-b14f-7fede6316c7c",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6ce93-01fe-4562-becf-45a872bfdbb8",
   "metadata": {},
   "source": [
    "It might seem like a lot of work to parse the received string into a dictionary, but there's a better approach which is typically taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2dc31-4e9c-402a-8dbd-73168d7b4284",
   "metadata": {},
   "source": [
    "What we're going to do is, in our `CustomDecoder`, we will call `json.loads()` on the received string - this deserialises the JSON string into a python dictionary with all default deserialisations applied e.g. `'[1, 2, 3]'` will be converted into a Python list `[1, 2, 3]`.  \n",
    "\n",
    "We can now convert those deserialised objects into whatever specific types we want.\n",
    "\n",
    "In the example below, we'll convert our list of `points`, each represented as a list of two values, into a point object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac8e7229-1377-4c87-b113-a7fa35ddda3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Point(x={self.x}, y={self.y})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2f206b-1327-4aba-a3b9-8ef1b195f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_points = '''\n",
    "{\n",
    "    \"points\": [\n",
    "        [10, 20],\n",
    "        [-1, -2],\n",
    "        [0.5, 0.5]\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "j_other = '''\n",
    "{\n",
    "    \"a\": 1,\n",
    "    \"b\": 2\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f506b7-c66b-4c8f-9bb9-7bd61552b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class CustomDecoder(json.JSONDecoder):\n",
    "\n",
    "    def decode(self, arg: str):  # remember that `decode` takes the original string\n",
    "        obj: dict = json.loads(arg)  # we delegate the rough business of string parsing to `json.loads`\n",
    "        if \"points\" in obj:\n",
    "            obj[\"points\"] = [Point(x, y) for x, y in obj[\"points\"]]\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca802617-45f7-4cf3-90ce-3a58d723b931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points': [Point(x=10, y=20), Point(x=-1, y=-2), Point(x=0.5, y=0.5)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(j_points, cls=CustomDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ab392d-2ade-438f-a889-db1e315221a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(j_other, cls=CustomDecoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a43001-f132-4216-a00d-fae5790adfc6",
   "metadata": {},
   "source": [
    "One limitation of this approach is that, even with `j_other`, we had to `json.loads()` the entire thing despite it not having the `\"points\"` key. An alternative approach which gets around this is by writing a regex pattern to match on the received string if it contains `\"_type\": \"point\"`. But there's a problem. Any amount of whitespace before and after the colon in a JSON string is still valid JSON, so if the received string contains `\"_type\"     :    \"point\"`, we would need to match for that too.\n",
    "\n",
    "I won't go into too many details, but in regex you can do this with a particular pattern: `pattern = r'\"_type\"\\s*:\\s*\"point\"'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d078cf87-a1a5-40b6-a1a7-8cfef98948ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\"_type\"\\s*:\\s*\"point\"'\n",
    "regexp = re.compile(pattern)  # compiling the pattern is useful if the pattern is used frequently throughout your program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79e4f240-fdef-4e63-b303-a2ff9570bb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(regexp.search('\"a\": 1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d38ba27e-37c1-40d5-ad60-d578bff8af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 19), match='\"_type\"   : \"point\"'>\n"
     ]
    }
   ],
   "source": [
    "print(regexp.search('\"_type\"   : \"point\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79ff27f6-982c-44a6-84bf-6cd3daa2cf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 19), match='\"_type\"  :  \"point\"'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(pattern, '\"_type\"  :  \"point\"')  # this is how you do it if you don't want to compile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004238e-6039-4368-9b17-191950410ad3",
   "metadata": {},
   "source": [
    "See below for an implementation - go to Section 7, Video 56 if you want more explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a6db31f-08fe-4c57-b965-0bdb7a57ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDecoder(json.JSONDecoder):\n",
    "    def decode(self, arg):\n",
    "        obj = json.loads(arg)\n",
    "        pattern = r'\"_type\"\\s*:\\s*\"point\"'\n",
    "        if re.search(pattern, arg):\n",
    "            # we have at least one `Point'\n",
    "            obj = self.make_pts(obj)\n",
    "        return obj\n",
    "    \n",
    "    def make_pts(self, obj):\n",
    "        # recursive function to find and replace points\n",
    "        # received object could be a dictionary, a list, or a simple type\n",
    "        if isinstance(obj, dict):\n",
    "            # first see if this dictionary is a point itself\n",
    "            if '_type' in obj and obj['_type'] == 'point':\n",
    "                # could have used: if obj.get('_type', None) == 'point'\n",
    "                obj = Point(obj['x'], obj['y'])\n",
    "            else:\n",
    "                # root object is not a point\n",
    "                # but it could contain a sub-object which itself \n",
    "                # is or contains a Point object\n",
    "                for key, value in obj.items():\n",
    "                    obj[key] = self.make_pts(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for index, item in enumerate(obj):\n",
    "                obj[index] = self.make_pts(item)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297740b3-2ee9-4303-b58b-c6bcf011d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = '''\n",
    "{\n",
    "    \"a\": 100,\n",
    "    \"b\": 0.5,\n",
    "    \"rectangle\": {\n",
    "        \"corners\": {\n",
    "            \"b_left\": {\"_type\": \"point\", \"x\": -1, \"y\": -1},\n",
    "            \"b_right\": {\"_type\": \"point\", \"x\": 1, \"y\": -1},\n",
    "            \"t_left\": {\"_type\": \"point\", \"x\": -1, \"y\": 1},\n",
    "            \"t_right\": {\"_type\": \"point\", \"x\": 1, \"y\": 1}\n",
    "        },\n",
    "        \"rotate\": {\"_type\" : \"point\", \"x\": 0, \"y\": 0},\n",
    "        \"interior_pts\": [\n",
    "            {\"_type\": \"point\", \"x\": 0, \"y\": 0},\n",
    "            {\"_type\": \"point\", \"x\": 0.5, \"y\": 0.5}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ec2c24c-75db-4322-9707-831723f2251a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 100,\n",
      " 'b': 0.5,\n",
      " 'rectangle': {'corners': {'b_left': Point(x=-1, y=-1),\n",
      "                           'b_right': Point(x=1, y=-1),\n",
      "                           't_left': Point(x=-1, y=1),\n",
      "                           't_right': Point(x=1, y=1)},\n",
      "               'interior_pts': [Point(x=0, y=0), Point(x=0.5, y=0.5)],\n",
      "               'rotate': Point(x=0, y=0)}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(json.loads(j, cls=CustomDecoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be104f3f-ae96-4fec-a335-7ce783e4160d",
   "metadata": {},
   "source": [
    "Let's say we also want to convert decimal values to Decimal points. We're going to need to hardcode `parse_float` in our initialisation: (see original notebook for other, more-readable way of doing this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcb46d51-1ffe-42b6-b9b2-ce90e35ba44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from decimal import Decimal\n",
    "import re\n",
    "\n",
    "class CustomDecoder(json.JSONDecoder):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(parse_float=Decimal)\n",
    "    \n",
    "    def decode(self, arg):\n",
    "        obj = super().decode(arg) \n",
    "        pattern = r'\"_type\"\\s*:\\s*\"point\"'\n",
    "        if re.search(pattern, arg):\n",
    "            # we have at least one `Point'\n",
    "            obj = self.make_pts(obj)\n",
    "        return obj\n",
    "    \n",
    "    def make_pts(self, obj):\n",
    "        # recursive function to find and replace points\n",
    "        # received object could be a dictionary, a list, or a simple type\n",
    "        if isinstance(obj, dict):\n",
    "            # first see if this dictionary is a point itself\n",
    "            if '_type' in obj and obj['_type'] == 'point':\n",
    "                # could have used: if obj.get('_type', None) == 'point'\n",
    "                obj = Point(obj['x'], obj['y'])\n",
    "            else:\n",
    "                # root object is not a point\n",
    "                # but it could contain a sub-object which itself \n",
    "                # is or contains a Point object\n",
    "                for key, value in obj.items():\n",
    "                    obj[key] = self.make_pts(value)\n",
    "        elif isinstance(obj, list):\n",
    "            for index, item in enumerate(obj):\n",
    "                obj[index] = self.make_pts(item)\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e937d3f1-0559-4b9c-9c18-c57aa3bb1247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 100,\n",
      " 'b': Decimal('0.5'),\n",
      " 'rectangle': {'corners': {'b_left': Point(x=-1, y=-1),\n",
      "                           'b_right': Point(x=1, y=-1),\n",
      "                           't_left': Point(x=-1, y=1),\n",
      "                           't_right': Point(x=1, y=1)},\n",
      "               'interior_pts': [Point(x=0, y=0), Point(x=0.5, y=0.5)],\n",
      "               'rotate': Point(x=0, y=0)}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "res = json.loads(j, cls=CustomDecoder)\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "242b6822-e006-4ed1-a8e9-8fb46252d69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decimal.Decimal"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res['rectangle']['interior_pts'][1].x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b9deb-f8e3-431d-b34e-0a449a23d0d5",
   "metadata": {},
   "source": [
    "# 07 - JSONSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c347bcd0-beab-49c2-a288-bb1cd76df49d",
   "metadata": {},
   "source": [
    "Often when we work with JSON data, the way the data is formatted is not haphazard - it often conforms to some very precise specification.\n",
    "\n",
    "For example, REST API's will conform to some specific format for JSON input and output. \n",
    "\n",
    "This is called conforming to a **schema**. It is very similar to how relational databases work - we have a schema that precisely defines the columns in tables, the relationships between tables and so on.\n",
    "\n",
    "One of the main reasons for having these schemas for JSON data is that it allows us to serialize and deserialize the data more easily - we know in advance what the JSON structure will look like, and we can therefore write code that will leverage our understanding of the JSON structure.\n",
    "\n",
    "There are many ways in which we can define a JSON schema - it could be as simple as creating a Word document that explains how the JSON needs to be structured. Although that works, there are better, standards-based approaches though.\n",
    "\n",
    "One of these is the JSON Schema standard:\n",
    "https://json-schema.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a19f9f-b17f-40ef-ab05-73e16c124458",
   "metadata": {},
   "source": [
    "Some terminology:\n",
    "\n",
    "- instance: Any JSON value (e.g., a number, string, object, array, etc.) that is being validated against the schema\n",
    "- schema: document that contains the description\n",
    "- [validation keywords](https://json-schema.org/draft/2020-12/json-schema-validation#section-6.1.1): Defines the constraints and requirements of the instance. Examples to follow on how these can be used. Some common words are:\n",
    "    - `\"type\"`: Data type of the instance.\n",
    "    - `\"minimum\"`\n",
    "    - `\"maxLength\"`\n",
    "    - `\"properties\"` Specifies what keys should be in the instance \n",
    "    - `\"additionalProperties\"` Indicates whether additional properties are allowed in the instance\n",
    "    - `\"enum\"`: Value must be one of the specified values in an array\n",
    "- [schema annotations](https://json-schema.org/draft/2020-12/json-schema-validation#section-9.1)]: \n",
    "Schema annotations in JSON Schema provide metadata and descriptive information about the schema or its parts. These annotations do not affect the validation of the JSON data but serve to offer additional context, documentation. Some common ones are:\n",
    "    - `\"title\"`: A short, descriptive title for the schema or a specific property\n",
    "    - `\"description\"`: A detailed description of the schema or property for context\n",
    "    - `\"default\"`: Specifies a default value for a property when no value is provided\n",
    "- [schema keywords](https://json-schema.org/draft/2020-12/json-schema-core#section-8.1.1): Refer to specific keywords used to provide meta information about the JSON Schema itself. Some common ones include:\n",
    "    - `\"$schema\"`: Specifies the version of the JSON Schema specification that the schema conforms to. For example, \"$schema\": \"http://json-schema.org/draft-07/schema#\" indicates that the schema follows the draft-07 version of the JSON Schema specification\n",
    "    - `\"$id\"`: Provides a unique identifier for the schema. This can be a URI that allows the schema to be referenced from other schemas.\n",
    "    - `\"$vocabulary\"`: This keyword is used to declare the core vocabulary that the schema uses, allowing for vocabulary composition and extension. Default vocabulary includes things like \"minimum\", \"maxLength\", etc., but custom vocabularies can be made too (https://json-schema.org/draft/2020-12/json-schema-core#name-the-vocabulary-keyword).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77778940-8cde-479d-81c2-027f36f4fc7c",
   "metadata": {},
   "source": [
    "Without going into much more detail, we'll show how it can be used with some examples. We can validate our schema with many different libraries in many different languages but here we'll use [jsonschema](https://github.com/Julian/jsonschema). You will need to `pip install jsonschema`\n",
    "\n",
    "Here's a schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385d1195-66f1-4db9-a3df-ab934de15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"firstName\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 1\n",
    "        },\n",
    "        \"middleInitial\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 1,\n",
    "            \"maxLength\": 1\n",
    "        },\n",
    "        \"lastName\": {\n",
    "            \"type\": \"string\",\n",
    "            \"minLength\": 1\n",
    "        },\n",
    "        \"age\": {\n",
    "            \"type\": \"integer\", \n",
    "            \"minimum\": 0\n",
    "        },\n",
    "        \"eyeColor\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"amber\", \"blue\", \"brown\", \"gray\", \n",
    "                     \"green\", \"hazel\", \"red\", \"violet\"]\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"firstName\", \"lastName\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b8c89-2f52-4443-a56a-8471c0c61d89",
   "metadata": {},
   "source": [
    "We can use the `validate` function, but it will not work with a string - it needs to be deserialized into a Python dictionary first (which means it will have to be a valid JSON structure first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758013d7-542d-4f98-9f5d-423e0c3fef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON is valid\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "\n",
    "p1 = '''\n",
    "    {\n",
    "        \"firstName\": \"John\",\n",
    "        \"middleInitial\": \"M\",\n",
    "        \"lastName\": \"Cleese\",\n",
    "        \"age\": 79\n",
    "    }\n",
    "'''\n",
    "\n",
    "try:\n",
    "    jsonschema.validate(json.loads(p1), person_schema)\n",
    "except json.JSONDecodeError as ex:\n",
    "    print(f'Invalid JSON: {ex}')\n",
    "except ValidationError as ex:\n",
    "    print(f'Validation error: {ex}')\n",
    "else:\n",
    "    print('JSON is valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9246848c-01cd-457b-a63e-b848278ec41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: 100 is not of type 'string'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['middleInitial']:\n",
      "    {'maxLength': 1, 'minLength': 1, 'type': 'string'}\n",
      "\n",
      "On instance['middleInitial']:\n",
      "    100\n"
     ]
    }
   ],
   "source": [
    "p2 = '''\n",
    "    {\n",
    "        \"firstName\": \"John\",\n",
    "        \"middleInitial\": 100,\n",
    "        \"lastName\": \"Cleese\",\n",
    "        \"age\": \"Unknown\"\n",
    "    }\n",
    "'''\n",
    "\n",
    "try:\n",
    "    jsonschema.validate(json.loads(p2), person_schema)\n",
    "except json.JSONDecodeError as ex:\n",
    "    print(f'Invalid JSON: {ex}')\n",
    "except ValidationError as ex:\n",
    "    print(f'Validation error: {ex}')\n",
    "else:\n",
    "    print('JSON is valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a7d01-5c37-47a5-bfda-660f195b3d7c",
   "metadata": {},
   "source": [
    "You'll notice that the validator only returns the first validation error it encounters. This can be changed to run the entire validation and return all the validation errors (if any), but utilizes a slightly different way of performing validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ecfaac-6975-41f5-b557-57225056c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonschema import Draft4Validator\n",
    "\n",
    "validator = Draft4Validator(person_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98dfd31-7c9e-4877-9570-ab49f5ecde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 is not of type 'string'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['middleInitial']:\n",
      "    {'maxLength': 1, 'minLength': 1, 'type': 'string'}\n",
      "\n",
      "On instance['middleInitial']:\n",
      "    100\n",
      "-----------\n",
      "'Unknown' is not of type 'integer'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['age']:\n",
      "    {'minimum': 0, 'type': 'integer'}\n",
      "\n",
      "On instance['age']:\n",
      "    'Unknown'\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "for error in validator.iter_errors(json.loads(p2)):\n",
    "    print(error, end='\\n-----------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e84b89-effd-4210-9b62-dfad8134fccf",
   "metadata": {},
   "source": [
    "The errors returned are `ValidationError` objects (below, we can see their `__repr__` (i think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e6c0fd4-9e34-48c9-b000-6b841bd2a25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<ValidationError: \"100 is not of type 'string'\">, <ValidationError: \"'Unknown' is not of type 'integer'\">]\n"
     ]
    }
   ],
   "source": [
    "errors = list(validator.iter_errors(json.loads(p2)))\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ff62e-790c-4365-95fb-cf8694d8501c",
   "metadata": {},
   "source": [
    "When we print each error, we get more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "807bef13-c01b-40e3-8c38-5a70969edcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 is not of type 'string'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['middleInitial']:\n",
      "    {'maxLength': 1, 'minLength': 1, 'type': 'string'}\n",
      "\n",
      "On instance['middleInitial']:\n",
      "    100\n",
      "--------------------------------------------------------------------------------\n",
      "100 is not of type 'string'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['middleInitial']:\n",
      "    {'maxLength': 1, 'minLength': 1, 'type': 'string'}\n",
      "\n",
      "On instance['middleInitial']:\n",
      "    100\n"
     ]
    }
   ],
   "source": [
    "print(errors[0])\n",
    "print('-'*80)\n",
    "print(errors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5b820-acba-433b-9e4b-c1c976484bac",
   "metadata": {},
   "source": [
    "To look at another example, we can see in the schema that `eyeColor` is not required, but if it's passed in, then it must be a string out of one the options. In this example, `eyeColor` is the **enumerated type** and \"amber\", \"blue\", \"brown\", etc. are the **enumerators**.\n",
    "\n",
    "Also, `\"middleInitial\"` must be a single character string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "263fd4bf-b336-4cc4-b881-db7a28e2bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None is not of type 'string'\n",
      "\n",
      "Failed validating 'type' in schema['properties']['middleInitial']:\n",
      "    {'maxLength': 1, 'minLength': 1, 'type': 'string'}\n",
      "\n",
      "On instance['middleInitial']:\n",
      "    None\n",
      "-----------\n",
      "'blue-gray' is not one of ['amber', 'blue', 'brown', 'gray', 'green', 'hazel', 'red', 'violet']\n",
      "\n",
      "Failed validating 'enum' in schema['properties']['eyeColor']:\n",
      "    {'enum': ['amber',\n",
      "              'blue',\n",
      "              'brown',\n",
      "              'gray',\n",
      "              'green',\n",
      "              'hazel',\n",
      "              'red',\n",
      "              'violet'],\n",
      "     'type': 'string'}\n",
      "\n",
      "On instance['eyeColor']:\n",
      "    'blue-gray'\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "p3 = '''\n",
    "    {\n",
    "        \"firstName\": \"John\",\n",
    "        \"middleInitial\": null,\n",
    "        \"lastName\": \"Cleese\",\n",
    "        \"eyeColor\": \"blue-gray\"\n",
    "    }\n",
    "'''\n",
    "\n",
    "for error in validator.iter_errors(json.loads(p3)):\n",
    "    print(error, end='\\n-----------\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc59593-9363-49a6-b605-c42d43c33f6c",
   "metadata": {},
   "source": [
    "So JSON Schema paired with this library is a great way to ensure a JSON document conforms to some specific schema. It is useful even when you create your own JSON serializer to make sure you are conforming to your own pre-determined schema - especially useful in unit testing to make sure you did not miss something when serializing your objects to JSON.\n",
    "\n",
    "But all this does not address the other issue we have - serializing and deserializing Python objects to and from JSON strings (marshalling). This is addressed in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36ab9a-6051-4582-9383-22489bd0725a",
   "metadata": {},
   "source": [
    "# 08 - Marshmallow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151c080-d27e-4fe6-b58a-ee0fe9999389",
   "metadata": {},
   "source": [
    "The original videos showed how this could be done using the Marshmallow library, however, Pydantic is now recommended. There is an entire summary on Fred Baptiste's Pydantic course found in this repo too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22cdc4-529b-4a4d-bc26-3f8fae03fd93",
   "metadata": {},
   "source": [
    "# 09 - YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a302a-192b-4cb0-aac8-6ebf1b353b09",
   "metadata": {},
   "source": [
    "# 10 - Serpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77084b49-ddb1-4ae3-aaad-8d7021a86726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
