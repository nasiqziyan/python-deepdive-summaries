{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7807ab61-c7a3-49df-abf6-520859b1d53f",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a609ce2-1ac0-4a70-b637-c554e1f56cc8",
   "metadata": {},
   "source": [
    "Serialising and deserialising objects is useful for persistence of data (even after a program has terminated) and/or transmission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b311673-51eb-471a-a8f9-53507d58e249",
   "metadata": {},
   "source": [
    "# 01 - Pickling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7086655b-ae3f-4c14-866f-3f7d42e0cf7a",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccfc6f-c7e5-48cd-894c-eb232d027ba0",
   "metadata": {},
   "source": [
    "This is a python-specific mechanism to serialise/deserialise objects using **binary** (by default) representation.\n",
    "\n",
    "While pickling applies to *more* than just python dictionaries, we will focus on dictionaries here because of JSON - it's easy to serialise/deserialise them into JSON.\n",
    "\n",
    "But not all data types are serialisable; `datetime`s, for example, don't serialise without loss of data, but there are 3rd party libraries that solve these problems (marshmallow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5d5c8-bbe8-4c95-ba75-56bcf2d1ae46",
   "metadata": {},
   "source": [
    "**Object/Data Marshalling** is the process of serialising **and** deserialising objects/data:\n",
    "\n",
    "`obj -- serialise --> 0101001110011... -- deserialise --> obj`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883f6e7-2aa9-46de-b2b1-dcb7aa22394c",
   "metadata": {},
   "source": [
    "Unpickling data can be **dangerous** because they can **execute code**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ef357-e977-43b9-801d-9b59b5dec2d9",
   "metadata": {},
   "source": [
    "##### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab684dc3-f81e-4aee-bd58-995c8bbbad68",
   "metadata": {},
   "source": [
    "```import pickle```\n",
    "\n",
    "`dump` -> pickle to file\n",
    "\n",
    "`load` -> unpickle from file\n",
    "\n",
    "`dumps` -> returns a string pickled representation that can be stored in a variable\n",
    "\n",
    "`loads` -> unpickles from a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b83d4-fa7b-42f8-bf43-494cc92e8713",
   "metadata": {},
   "source": [
    "##### Equality and Identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6bd14-4f41-4f5b-9d39-ce48978f09a5",
   "metadata": {},
   "source": [
    "A pickled object does not contain information of its ID. Therefore, if a dictionary `dict_1` is pickled and then unpickled, the final dictionary `dict_2` will have a different ID to the original.\n",
    "\n",
    "`dict_1 == dict_2` but `dict_1 is not dict_2`\n",
    "\n",
    "Serialising/Deserialising data behaves very similar to making deepcopies. If we deepcopy an object which contains two identical references to the same object, then, the copy will ensure that the relationship is maintained. To elaborate with an example:\n",
    "\n",
    "```python\n",
    "my_list = [1, 2]\n",
    "l1 = ['a', 'b', my_list, my_list]\n",
    "\n",
    "l1[2] == l1[3] --> True\n",
    "l1[2] is l1[3] --> True\n",
    "\n",
    "l2 = deepcopy(l1)\n",
    "l2 -> ['a', 'b', [1, 2], [1, 2]]\n",
    "\n",
    "l2[2] == l2[3] --> True\n",
    "l2[2] is l2[3] --> True\n",
    "```\n",
    "\n",
    "So Python sees the shared reference of `l1[2]` and `l2[3]` pointing to `my_list` and it replicates that relationship in the copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a515702-7860-4e60-b22c-6267ac896776",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb12ce-8fc9-4f9c-8538-5c9e1894fff7",
   "metadata": {},
   "source": [
    "##### `.dumps()` and `.loads()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc8355-3d91-4242-ad59-3e2227d6f7a3",
   "metadata": {},
   "source": [
    "We can pickle **strings**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df82eedf-1fd1-4592-a28d-603d825500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a34974-b983-4ef7-85df-594784fac5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x15Python Pickle Peppers\\x94.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps('Python Pickle Peppers')\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149ba4c7-09f7-416f-ba53-0281cda6519c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python Pickle Peppers'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d21217-5163-4e9a-b735-092856b9a6a9",
   "metadata": {},
   "source": [
    "And **floats/integers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea45278f-6bb0-4a54-8c12-4077475e6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00G@\\t\\x1e\\xb8Q\\xeb\\x85\\x1f.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps(3.14)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf76488-11a8-4028-ba0f-6055fde36788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4b451-37df-475b-92bf-ddbebab566e0",
   "metadata": {},
   "source": [
    "And **sets**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "759a4f5d-b59d-4b55-af4c-11fcbc157869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x0f\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8f\\x94(\\x8c\\x01a\\x94K\\n\\x8c\\x01b\\x94\\x90.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pickle.dumps({'a', 'b', 10})\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f08cf3ed-3953-4918-934e-458d68957077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 'a', 'b'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405dbf9-e01e-4751-9378-b5a1eb552a76",
   "metadata": {},
   "source": [
    "And **lists/tuples**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de90d34-8340-4877-8195-2e110254991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x15\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(K\\nK\\x14\\x8c\\x01a\\x94\\x8c\\x01b\\x94K\\x1e\\x87\\x94e.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [10, 20, ('a', 'b', 30)]\n",
    "ser = pickle.dumps(l1)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28c7745a-df58-45e0-84b4-8086f06c9e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 20, ('a', 'b', 30)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = pickle.loads(ser)\n",
    "l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde68b58-57cf-44ad-91bf-f4e815dc4a79",
   "metadata": {},
   "source": [
    "But remember that the IDs will **change**. They are **equal** but not **identical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4748737-5fc4-48d1-8f54-be7d25c6be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 == l2 = True\n",
      "l1 is l2 = False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{l1 == l2 = }\")\n",
    "print(f\"{l1 is l2 = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc83bc2-4e88-4075-81fc-8550acb3465e",
   "metadata": {},
   "source": [
    "And **dictionaries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c950c44-396e-4099-97e3-a0a6ec9bc7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x04\\x95\\x8b\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x94(\\x8c\\x01a\\x94Kd\\x8c\\x01b\\x94]\\x94(K\\x01K\\x02K\\x03e\\x8c\\x01c\\x94K\\x01K\\x02K\\x03\\x87\\x94\\x8c\\x01d\\x94}\\x94(\\x8c\\x01x\\x94\\x8c\\x08builtins\\x94\\x8c\\x07complex\\x94\\x93\\x94G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00\\x86\\x94R\\x94\\x8c\\x01y\\x94\\x8c\\x08datetime\\x94\\x8c\\x08datetime\\x94\\x93\\x94C\\n\\x07\\xe8\\x01\\x1c\\x13: \\x07\\x94\\xda\\x94\\x85\\x94R\\x94uu.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "d = {\n",
    "    'a': 100,\n",
    "    'b': [1, 2, 3],\n",
    "    'c': (1, 2, 3),\n",
    "    'd': {'x': 1 + 1j, 'y': datetime.utcnow()}\n",
    "}\n",
    "\n",
    "ser = pickle.dumps(d)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a9451d-e150-4fa9-984c-def79398b226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 100,\n",
       " 'b': [1, 2, 3],\n",
       " 'c': (1, 2, 3),\n",
       " 'd': {'x': (1+1j), 'y': datetime.datetime(2024, 1, 28, 19, 58, 32, 496858)}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deser = pickle.loads(ser)\n",
    "deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac9c49-b7bf-4984-8a4f-cc84a906c556",
   "metadata": {},
   "source": [
    "As mentioned in the lecture, shared reference relationships are maintained with serialising/deserialising just like with deepcopies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f57e95-5e6e-44f2-8dc7-b608661df944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'a': 10, 'b': 20}\n",
    "d = {'x': 100, 'y': my_dict, 'z': my_dict}\n",
    "\n",
    "print(d['y'] == d['y'])\n",
    "print(d['y'] is d['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23462cc6-437b-4a7f-b680-78caf257ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ser = pickle.dumps(d)\n",
    "d2 = pickle.loads(ser)\n",
    "\n",
    "print(d2['y'] == d2['y'])\n",
    "print(d2['y'] is d2['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9168a-990e-46a9-a149-d2f430767e8c",
   "metadata": {},
   "source": [
    "# 02 - JSON Serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a651b-dc8f-4ba6-8276-7e86edd1c4d9",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef773b-6770-41c9-be76-d65aa106a9ec",
   "metadata": {},
   "source": [
    "JSON has just a few data types it supports:\n",
    "\n",
    "* **Strings**: must be delimited by double quotes\n",
    "* **Booleans**: the values `true` and `false`\n",
    "* **Numbers**: can be integers, or floats (including exponential notation, `1.3E2` for example), but are all considered **floats** in the standard\n",
    "* **Arrays**: an **ordered** collection of zero or more items of any valid JSON type\n",
    "* **Objects**: an **unordered** collection of `key:value` pairs - **the keys must be strings (so delimited by double quotes)**, and the values can be any valid JSON type.\n",
    "* **NULL**: a null object, denoted by `null` and equivalent to `None` in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7434f-240f-436c-9e4c-cbaa9c9c298b",
   "metadata": {},
   "source": [
    "Python dictionaries are **objects** while JSON is essentially a **string**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c0b51-c4e8-4949-baf9-2bc9d9dc731c",
   "metadata": {},
   "source": [
    "##### Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebabcd-194d-4d32-aab5-046227e211f2",
   "metadata": {},
   "source": [
    "- JSON keys must be strings, but python dictionary keys just need to be hashable. So if you had an `integer` as a key in your python dictionary, how will you serialise it?\n",
    "- JSON value types are limited to those above. So we can't have tuples, datetime objects, `Decimal`'s `Fraction`'s, custom classes - how do we serialise these back to their original object?\n",
    "\n",
    "Solution? **Custom Serialisation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2b942-b371-4b64-a0d4-4a6b0066022c",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ce692-6d7c-48cf-8b53-81369f0f153b",
   "metadata": {},
   "source": [
    "Serialisation and deserialisation is very similar to pickling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d9ca9-c14d-4824-9abb-c6ec458575b3",
   "metadata": {},
   "source": [
    "```import json```\n",
    "\n",
    "`dump` -> dump to file\n",
    "\n",
    "`load` -> load from file\n",
    "\n",
    "`dumps` -> dumps python object to a string containing JSON\n",
    "\n",
    "`loads` -> loads a string containing JSON into a python object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999f54e-52bc-4e08-a886-59f8ed4bbecb",
   "metadata": {},
   "source": [
    "`dump` and `dumps` have additional arguments for controlling serialisation:\n",
    "- `skipkeys: Bool = False`: if we are dumping a python dictionary, then the key must be one of the basic types and hashable. If set to true, then unserialisable keys will be skipped.\n",
    "- `indent: int = None`: useful for human readability\n",
    "- `separators: tuple = (\", \", \": \")`: the first argument customises how key-value pairs are separated and the 2nd customises how keys are separated from their values.\n",
    "\n",
    "   We can use this to compact the JSON object for small performance improvements.\n",
    "\n",
    "  Note, we still need a valid JSON, so the most compact form is having `indent = None` and `separators = (\",\",\":\")`\n",
    "- `sort_keys: bool = False`: if `True` the JSON string will have sorted keys. Since the keys will be strings, they will be alphanumerically sorted.\n",
    "\n",
    "and more..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238e445-351c-4ff1-9487-46c003b42c1b",
   "metadata": {},
   "source": [
    "We have a `pprint` equivalent for JSON which is achieved using the `indent` parameter of `json.dumps()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4fe7d01-c1ec-4402-85bc-5d2de84eef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": 100, \"b\": 200, \"c\": [1, 2, 3]} \n",
      "\n",
      "{\n",
      "  \"a\": 100,\n",
      "  \"b\": 200,\n",
      "  \"c\": [\n",
      "    1,\n",
      "    2,\n",
      "    3\n",
      "  ]\n",
      "} \n",
      "\n",
      "{\n",
      "___\"a\": 100,\n",
      "___\"b\": 200,\n",
      "___\"c\": [\n",
      "______1,\n",
      "______2,\n",
      "______3\n",
      "___]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "d1 = {'a': 100, 'b': 200, 'c': [1, 2, 3]}\n",
    "d1_json = json.dumps(d1)\n",
    "\n",
    "print(json.dumps(d1), \"\\n\")\n",
    "print(json.dumps(d1, indent=2), \"\\n\")\n",
    "print(json.dumps(d1, indent='___'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab16fb-7be1-42f9-a4fe-edd8d4588d35",
   "metadata": {},
   "source": [
    "##### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8c192-8fc1-4a4e-9eb0-3a9aa74e9492",
   "metadata": {},
   "source": [
    "As we said, json keys must be strings. So what if we serialise a deserialise objects with non-string keys? Do we get the same object back? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e2591f-33eb-4b96-8373-074fc3e50844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 100, '2': 200}\n"
     ]
    }
   ],
   "source": [
    "d1 = {1: 100, 2: 200}\n",
    "d1_json = json.dumps(d1, indent=2)\n",
    "d2 = json.loads(d1_json)\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086fb64-7ad2-4260-8be6-7662132b7589",
   "metadata": {},
   "source": [
    "The keys are **different**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1280bf-3805-42ad-94e3-43a638c27b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 == d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d99de-224a-4893-9d03-43752d60f42a",
   "metadata": {},
   "source": [
    "##### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035af8d-a580-4607-b67b-9b9f17baa53b",
   "metadata": {},
   "source": [
    "How will Python handle unsupported types such as tuples for the dictionary values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0b29a23-2cb8-415f-8be2-d6acf7e07442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\": [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "d = {'a': (1, 2, 3)}\n",
    "ser = json.dumps(d)\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60bf0d89-e802-4019-a0ca-83e31c425e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "deser = json.loads(ser)\n",
    "print(deser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ab252-b234-447b-a9c0-a05c7d588dac",
   "metadata": {},
   "source": [
    "The tuple was coerced into a list. Therefore, the value is **different**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f91a9af-28e1-471a-b735-482d774e6999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser == deser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8a13f-c6ea-4d10-a231-dfd03087c524",
   "metadata": {},
   "source": [
    "But, python at least tried to find the most similar thing to a tuple. With more complex objects such as datetime objects, `Decimal`s and class instances, it will raise `TypeError`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45bb3884-94c6-4dc0-b6a6-6eb31de4c4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of type datetime is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "from datetime import datetime\n",
    "\n",
    "try:    \n",
    "    json.dumps({'a': datetime(2024, 12, 23, 13, 37), 'b': Decimal(0.5)})\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137a359-4e7d-4c49-a259-ec3c991a9e60",
   "metadata": {},
   "source": [
    "# 03 - Custom JSON Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73862f7-4335-422e-96b4-ac51eec3c814",
   "metadata": {},
   "source": [
    "##### `datetime` objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7c189-6730-4643-9d86-c7d204a5720f",
   "metadata": {},
   "source": [
    "Python cannot serialise certain data types by itself but we can tell it how to. `json.dump()` and `json.dumps()` have a parameter caled `default`. This takes a callable that takes only one argument which is called on any objects that cannot be serialised by python itself. For example the `str()` will convert any unserialiable object to its string representation which can be serialised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6969c6b0-2fe7-4306-8b30-a6d8e19626cf",
   "metadata": {},
   "source": [
    "Often we will come up with our custom format or use industry standards. For example, datetime objects use the **ISO 8601** (https://en.wikipedia.org/wiki/ISO_8601).\n",
    "\n",
    "This has the format of:\n",
    "*YYYY-MM-DD***T***HH:MM:SS*\n",
    "\n",
    "The **T** is a character to separate the date from the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a702e8-4485-4228-a50e-538e5744884b",
   "metadata": {},
   "source": [
    "Note: the `str` representation of a time is not the same as the ISO format; it's similar but more human readable. As you can see it does not contain the required **T** character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e28521e2-ba77-403c-8390-19d3b8e38427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17 17:45:31.612621'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf4fee-9a2f-4fb4-911f-b970741ca606",
   "metadata": {},
   "source": [
    "If you want to format the year, month, day, time etc, in a particular way, use **`.strftime()` method** of datetime objects. \n",
    "\n",
    "The reverse of this method is `strptime()` which takes a string in a particular format and converts it to a datetime object.\n",
    "\n",
    "In the format, you indicate the different time components with directives. For example, `'%Y'` returns a 4 digit year e.g. 2012, where `'&y'` returns a year without century, zero-padded e.g. 2012 -> 12.\n",
    "\n",
    "Here's our custom, simple ISO format (without including timezones etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "141736fd-077b-450f-9e6a-dca98e686856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17T17:52:25'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_iso(dt):\n",
    "    return dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "format_iso(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e951697-f05e-4067-a1ca-d289fd75518c",
   "metadata": {},
   "source": [
    "Alternatively, we can use the inbuilt ISO format in `datetime` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b7df0e8-c35e-4bb4-a231-d8fdda84db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-17T17:53:46.213212'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a904aeda-bede-48fd-b323-16f528b61d34",
   "metadata": {},
   "source": [
    "Now lets serialise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd798d53-d909-40a3-aff5-c9d5a0ebb752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"time\": \"2024-02-17T17:55:55\"}\n"
     ]
    }
   ],
   "source": [
    "log_record = {'time': datetime.utcnow()}\n",
    "print(json.dumps(log_record, default=format_iso))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732cd83-7343-49f0-b67c-15175bac5b56",
   "metadata": {},
   "source": [
    "##### `singledispatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd074e4b-3d78-46bc-abcd-f1c862946dc8",
   "metadata": {},
   "source": [
    "If our `log_record` dictionary contained an unserialisable type that was *not* a datetime object, we're going to run into issues because the same callable will be used on it.\n",
    "\n",
    "We can get around this by checking the type of argument in the callable and handling it that way. For example, if we only had `datetime`s and `set`, this could work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d371e7-f9ce-4e6d-b6da-42f93bb3dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_json_formatter(arg):\n",
    "    if isinstance(arg, datetime):\n",
    "        return arg.isoformat()\n",
    "    elif isinstance(arg, set):\n",
    "        return list(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3e3744-c981-46b4-8cc3-7c3af49e7870",
   "metadata": {},
   "source": [
    "Obviously this doesn't scale well, so we should move over to using a `singledispatch`:\n",
    "\n",
    "Let's write a single dispatcher that registers specific implementations for `datetime`, `set`, `Decimal` - and for anything else, use their string representation. \n",
    "\n",
    "To do that, we first need to write the default behaviour which is stringifying the object. Then, we register our individual types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9717af38-1af3-4871-bf6a-95d0d15ccc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import singledispatch\n",
    "from decimal import Decimal\n",
    "\n",
    "@singledispatch\n",
    "def json_format(arg):\n",
    "    return str(arg)\n",
    "\n",
    "@json_format.register(datetime)\n",
    "def _(arg):\n",
    "    return arg.isoformat()\n",
    "\n",
    "@json_format.register(set)\n",
    "def _(arg):\n",
    "    return list(arg)\n",
    "\n",
    "@json_format.register(Decimal)\n",
    "def _(arg):\n",
    "    return f\"Decimal({str(arg)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83c07160-2f44-43f4-b2b4-3ea8dd627ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"time\": \"2024-02-17T18:26:58.562067\",\n",
      "  \"message\": \"Created new person\",\n",
      "  \"person\": \"Person(name=John, age=24)\",\n",
      "  \"complex_number\": \"(1+1j)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.create_dt = datetime.utcnow()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Person(name={self.name}, age={self.age})'\n",
    "\n",
    "log_record = dict(\n",
    "    time=datetime.utcnow(),\n",
    "    message='Created new person',\n",
    "    person=Person('John', 24),\n",
    "    complex_number = 1 + 1j,\n",
    ")\n",
    "\n",
    "print(json.dumps(log_record, indent=2, default=json_format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfda76b2-ce0d-4b62-a256-d71edcf669ad",
   "metadata": {},
   "source": [
    "# 04 - Custom Encoding using JSONEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea7b297-647f-419a-b1db-fbed03d92a0f",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cae5d-e651-45c4-909e-17aef18e94ca",
   "metadata": {},
   "source": [
    "Python already uses the `JSONEncoder` class in the `json` module we use `json.dumps()` for serialisation.\n",
    "\n",
    "The `JSONEncoder` shares many arguments with `dump`/`dumps`: `default`, `skipkeys`, `sort_keys`, `indent`, `separators`, ...\n",
    "\n",
    "But `dump`/`dumps` has one extra: `cls`: this allows us to specify our **own** version of `JSONEncoder` to be used when `dump`/`dumps` runs.\n",
    "\n",
    "The reason why we would want to make our own `JSONEncoder` class is so that we can define our arguments (`default`, `skipkeys`, `indent`, etc.) once and then apply it to all of our `json.dumps()` calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aceb0-a44a-479f-8a8c-e430206d2cc3",
   "metadata": {},
   "source": [
    "**Procedure**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db9a92-c1c6-43fe-885f-a6d23a32efc8",
   "metadata": {},
   "source": [
    "1. Subclass `JSONEncoder`.\n",
    "2. Customise initialiser of the **parent** class with the specific arguments that we want. (`super().__init__(skipkeys=True, allow_nan=False)`.)\n",
    "3. Override the `default` method if we want. If we do not, we can auto-delegate back to the parent class. `else: return super().default(self, arg)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9808fea-3bea-49c7-ab45-184736572a6a",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a5b1e-a5c8-4882-a33a-34561f63b7b9",
   "metadata": {},
   "source": [
    "To get a handle on the default encoder, we just create an instance of `JSONEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9c2975-8719-4077-b74e-d7f8458236ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "null\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "default_encoder = json.JSONEncoder()\n",
    "print(default_encoder.encode(True))\n",
    "print(default_encoder.encode(None))\n",
    "print(default_encoder.encode((1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787540a6-0f14-4e41-8413-3e6bb2948c86",
   "metadata": {},
   "source": [
    "Now for our custom one. Note that our `CustomJSONEncoder` inherits from `json.JSONEncoder`. `json.dumps()` passes all of its arguments to the `cls` argument, which is `CustomJSONEncoder` in our case, as `*args` and `**kwargs` .\n",
    "\n",
    "We don't do anything we these `*args` and `**kwargs` but we do define which ones we want and explicitly pass them to the superclass. When `encode` is called on our `customJSONEncoder`, it will call the `encode` method of the superclass (`json.JSONEncoder`), which will make use of our explictly passed parameters that we initialised earlier in the superclass.\n",
    "\n",
    "The entire serialisation implementation is done in the superclass `json.JSONEncoder`, except those methods that we've overridden such as `default`. \n",
    "\n",
    "So, when `json.dumps()` requires `default()` to pass a particular value, it will use our overridden implementation, not the one from the superclass.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b484c168-23ec-4d09-9777-f248c83d4d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            skipkeys=True,\n",
    "            allow_nan=False,\n",
    "            indent='___',\n",
    "            separators=('',' = ')\n",
    "        )\n",
    "\n",
    "    # overriding original default with ours\n",
    "    def default(self, arg):\n",
    "        if isinstance(arg, datetime):\n",
    "            datetime_dict = dict(\n",
    "                datatype=\"datetime\",\n",
    "                iso=arg.isoformat(),\n",
    "                date=arg.date().isoformat(),\n",
    "                time=arg.time().isoformat(),\n",
    "                year = arg.year\n",
    "            )\n",
    "            return datetime_dict\n",
    "        else:\n",
    "            super().default(arg)\n",
    "\n",
    "custom_encoder = CustomJSONEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44159d31-ff0c-4d87-8fb7-4e6dd697d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "___\"datatype\" = \"datetime\"\n",
      "___\"iso\" = \"2024-02-24T14:44:30.597643\"\n",
      "___\"date\" = \"2024-02-24\"\n",
      "___\"time\" = \"14:44:30.597643\"\n",
      "___\"year\" = 2024\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(custom_encoder.encode(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fe972c2-56f2-4102-bafd-a13d919b2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object of type set is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(custom_encoder.encode({1, 2, 3}))\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2938fb55-4f99-4cf8-aef5-48554f1273e8",
   "metadata": {},
   "source": [
    "Now for dumping. Note that we pass the *class* itself and not the class instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b613d77-4205-49b7-8045-723aef255b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "___\"name\" = \"test\"\n",
      "___\"time\" = {\n",
      "______\"datatype\" = \"datetime\"\n",
      "______\"iso\" = \"2024-02-18T16:34:19.151692\"\n",
      "______\"date\" = \"2024-02-18\"\n",
      "______\"time\" = \"16:34:19.151692\"\n",
      "______\"year\" = 2024\n",
      "___}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "my_dict = dict(name='test', time=datetime.now())\n",
    "print(json.dumps(my_dict, cls=CustomJSONEncoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8f02f-daa9-470b-b72d-ef99c8356aad",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "- You might've noticed the `*args, **kwargs` in our custom class' `__init__`. This is because `json.dumps()` will pass the default arguments of `json.dumps()` to the class in its `cls` argument. In other words, `json.dumps(my_dict)` is identical to `json.dumps(my_dict, skipkeys=False, allow_nan=True, ...)` because those are the default arguments.\n",
    "- `default` does not need to return a single value. In our case, we've serialised the datetime object into a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c73cf1-14b6-4c5e-a746-39b9d7d80cd2",
   "metadata": {},
   "source": [
    "# 05 - Custom JSON Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4066f-5684-4119-ae32-5d21475a3cff",
   "metadata": {},
   "source": [
    "#### Lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0dcf3f-e1e8-4265-8325-efa7c3525438",
   "metadata": {},
   "source": [
    "##### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa972149-86c0-4073-9074-e085a86a6cc8",
   "metadata": {},
   "source": [
    "When we use `json.load()` / `json.loads()`, the simple standard types i.e. strings, booleans, numbers (int/float), arrays and objects (dictionaries) will work out the box. \n",
    "\n",
    "**`load()`/`loads()` has some optional arguments:**\n",
    "- `object_hook`: **Callable** - This is called on every object (dictionary) including the root object (dictionary) that encloses the entire json object. This callable returns another dictionary which replaces the original object. This is very similar to the `default` argument we saw in the `dump`/`dumps` functions - but works for decoding instead of encoding.\n",
    "\n",
    "    For example, if we had:\n",
    "  ```python\n",
    "  data = {'username': 'John',\n",
    "          'createdAt': {objecttype='datetime', value='2018-10-21T09:14:15'}\n",
    "  ```\n",
    "  We could write a function `custom_decoder` that takes a dictionary, looks to see if it has a key called with `objecttype='datetime' and if so, converts the value to a datetime object and returns the new decoded dictionary.\n",
    "\n",
    "  So, `custom_decoder(data) ->`\n",
    "  ```python\n",
    "  data = {'username': 'John',\n",
    "          'createdAt': {objecttype='datetime', value=Datetime(2024, 10, 21, 09, 14, 15}\n",
    "          }\n",
    "  ``` \n",
    "\n",
    "\n",
    "    Note: when `object_hook` is provided, this procedure only occurs *after* the initial `deserialisation` - that which occurs when no `object_hook` is provided; that is, `object_hook` and `object_pairs_hook` receives a **parsed** object which may have be parsed using one of the `parse_...` arguments **first** (see below).\n",
    "\n",
    "    This initial deserialisation converts e.g. `j = '''{\"a\": [1, 2]}'''` into a dictionary where the keys and values are the appropriate types, e.g. '[1, 2]' into a list object.\n",
    "  ```python\n",
    "  j = '''\n",
    "      { # root dictionary\n",
    "          \"a\": 1, \n",
    "          \"b\": {\n",
    "             \"sub1\": [1, 2, 3],\n",
    "             \"sub2\": {\n",
    "                   \"x\": 100,\n",
    "                   \"y\": 200\n",
    "              }\n",
    "          }\n",
    "      }     \n",
    "      '''\n",
    "  ```\n",
    "  `sub2`, `b` and `root` are all dictionaries that will be passed to the `object_hook` callable in that order - from the inner to the out. The `root` is always called last.\r",
    "<br/><br/>\n",
    "- `object_pairs_hook`: Related to `object_hook`. We can't use both at the same time; if both specified, `object_hook` ignored. First note that order of items in your json string is not necessarily preserved upon deserialising, but lists preserve order: deserialising '[1, 2, 3]' will always be `[1, 2, 3]`. `object_hook_pairs` behaves identical to `object_hook` except instead of passing a dictionary to the callable, a list of key-value tuples will be passed instead:\n",
    "    - `object_hook` recevies: `{\"a\": 1, \"b\": 2}`\n",
    "    - `object_pairs_hook` receives: `[ (\"a\", 1), (\"b\", 2) ]`\n",
    "\n",
    "    With this, we are guaranteed order of keys seen in the initial json string.<br/><br/> \n",
    "- `parse_float`, `parse_int`, `parse_constant`: **Callable** with single str argument - Remember that we could custom serialise `Fraction(3, 2)` to the number 1.5. Well, what if we got a JSON containing the number 1.5 and we wanted to deserialise to `Fraction(3, 2)`? \n",
    "\n",
    "    This would require overriding the **initial deserialisation** that occurs before `object_hook`. Depending on what the value is in the JSON, we would use either `parse_float`, `parse_int` or `parse_constant` (relevant for Infinity, NaN, etc.) to override its deserialisation before. Note that we cannot override strings. Here's an example:\n",
    "\n",
    "    ```python\n",
    "    from decimal import Decimal\n",
    "\n",
    "    def make_decimal(arg: str):\n",
    "        return Decimal(arg)\n",
    "    j = '''{\"a\": 100.5}'''\n",
    "    res = json.loads(j, parse_float=make_decimal)\n",
    "\n",
    "    res -> {\"a\": Decimal('100.5')}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02cf2d-6818-4e29-8417-03d4b4feeba2",
   "metadata": {},
   "source": [
    "##### Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08764397-9721-4cd4-9769-f3a5efa3d103",
   "metadata": {},
   "source": [
    "We need to know the structure of the JSON data in order to perform custom **deserialisation**. This structure is called a **schema** - a pre-defined agreement on how the JSON is going to be **serialised**.\n",
    "\n",
    "The schema does not need to be for the entire JSON; it can be for subcomponents only.\n",
    "\n",
    "This is an example JSON schema for dealing with fractions:\n",
    "```python\n",
    "j = '''\n",
    "    {\n",
    "        \"cake\": \"yummy chocolate cake\",\n",
    "        \"myShare\": {\n",
    "            \"objecttype\": \"fraction\",\n",
    "            \"numerator\": 1,\n",
    "            \"denominator\": 8\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "```\n",
    "\n",
    "We can use this to create a `Fraction` object with the appropriate numerator and denominator that will replace the original value of the `myShare` key. \n",
    "\n",
    "As you can imagine, we can define numerous dictionaries with different `objecttype` and handle each of them accordingly. \n",
    "\n",
    "The way to do this in a *less clunky* way is using `object_hook`. This is like the decode equivalent of the `default` argument which was used for encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1035fc9-c743-42f2-9aa3-67c679b5c085",
   "metadata": {},
   "source": [
    "#### Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71a208-8d0b-4d76-8cf0-d80decaa92fc",
   "metadata": {},
   "source": [
    "Let's make some JSON data and write our custom decoder which takes a dictionary and **replaces it** with an appropriate python type. We will take datetimes strings and parse them into datetime objects and fraction strings and parse them into Fraction objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05d45b6-69ee-4055-85ca-9501bb186c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cake': 'yummy chocolate cake',\n",
      " 'myShare': Fraction(1, 8),\n",
      " 'times': {'created': datetime.datetime(2018, 10, 21, 9, 14, 15),\n",
      "           'updated': datetime.datetime(2018, 10, 22, 10, 0, 5)}}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from pprint import pprint\n",
    "from fractions import Fraction\n",
    "\n",
    "j = '''\n",
    "    {\n",
    "        \"times\": {\n",
    "            \"created\": {\n",
    "                \"objecttype\": \"datetime\",\n",
    "                \"value\": \"2018-10-21T09:14:15\"\n",
    "                },\n",
    "            \"updated\": {\n",
    "                \"objecttype\": \"datetime\",\n",
    "                \"value\": \"2018-10-22T10:00:05\"\n",
    "                }\n",
    "            },\n",
    "\n",
    "        \"cake\": \"yummy chocolate cake\",\n",
    "        \"myShare\": {\n",
    "            \"objecttype\": \"fraction\",\n",
    "            \"numerator\": 1,\n",
    "            \"denominator\": 8\n",
    "        }\n",
    "    }\n",
    "'''\n",
    "\n",
    "def custom_decoder(arg: dict):\n",
    "    if \"objecttype\" in arg:\n",
    "        if arg[\"objecttype\"] == \"datetime\":\n",
    "            return datetime.strptime(arg[\"value\"], \"%Y-%m-%dT%H:%M:%S\")\n",
    "        \n",
    "        elif arg['objecttype'] == 'fraction':\n",
    "            return Fraction(arg['numerator'], arg['denominator'])\n",
    "\n",
    "        return arg\n",
    "\n",
    "    else:\n",
    "        return arg\n",
    "\n",
    "pprint(json.loads(j, object_hook=custom_decoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022befb5-8fe0-421a-830e-bc0df6d44b0f",
   "metadata": {},
   "source": [
    "We **need** the `return arg` blocks because the root dictionary of the JSON will always be passed to the `object_hook` callable. Without the block, when the root dictionary is passed in, the decoder will return `None` and it'll be replaced with `None`. Therefore, `json.loads()` returns `None` overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928d198-9de0-43a1-aadd-3cd226207a57",
   "metadata": {},
   "source": [
    "# 06 - Using JSONDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288b9deb-f8e3-431d-b34e-0a449a23d0d5",
   "metadata": {},
   "source": [
    "# 07 - JSONSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36ab9a-6051-4582-9383-22489bd0725a",
   "metadata": {},
   "source": [
    "# 08 - Marshmallow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22cdc4-529b-4a4d-bc26-3f8fae03fd93",
   "metadata": {},
   "source": [
    "# 09 - YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090a302a-192b-4cb0-aac8-6ebf1b353b09",
   "metadata": {},
   "source": [
    "# 10 - Serpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77084b49-ddb1-4ae3-aaad-8d7021a86726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
